{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch as t\n",
    "import einops\n",
    "from typing import Dict, List\n",
    "import torch.sparse as sparse\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch as t\n",
    "import torch.sparse as sparse\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from typing import Dict, List\n",
    "from pathlib import Path\n",
    "\n",
    "from trainers.scae import SCAESuite\n",
    "from buffer import AllActivationBuffer\n",
    "from utils import load_model_with_folded_ln2, load_iterable_dataset\n",
    "from find_top_connections import get_importance_scores\n",
    "from trainers.top_k import AutoEncoderTopK\n",
    "\n",
    "DTYPE = t.bfloat16\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "t.manual_seed(42)\n",
    "t.set_grad_enabled(False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/dictionary_learning/connections_100.pkl\", \"rb\") as f:\n",
    "    connections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/notebooks/../trainers/scae.py:653: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  \n",
      "/root/dictionary_learning/notebooks/../buffer.py:237: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  t.cuda.amp.autocast(dtype=self.dtype)\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "model = load_model_with_folded_ln2(\"gpt2\", device=device, torch_dtype=DTYPE)\n",
    "data = load_iterable_dataset('Skylion007/openwebtext')\n",
    "suite = SCAESuite.from_pretrained(\n",
    "    'jacobcd52/gpt2_suite_folded_ln',\n",
    "    device=device,\n",
    "    dtype=DTYPE,\n",
    "    )\n",
    "\n",
    "initial_submodule = model.transformer.h[0]\n",
    "layernorm_submodules = {}\n",
    "submodules = {}\n",
    "for layer in range(model.config.n_layer):\n",
    "    submodules[f\"mlp_{layer}\"] = (model.transformer.h[layer].mlp, \"in_and_out\")\n",
    "    submodules[f\"attn_{layer}\"] = (model.transformer.h[layer].attn, \"out\")\n",
    "\n",
    "    layernorm_submodules[f\"mlp_{layer}\"] = model.transformer.h[layer].ln_2\n",
    "\n",
    "buffer = AllActivationBuffer(\n",
    "    data=data,\n",
    "    model=model,\n",
    "    submodules=submodules,\n",
    "    initial_submodule=initial_submodule,\n",
    "    layernorm_submodules=layernorm_submodules,\n",
    "    d_submodule=model.config.n_embd,\n",
    "    n_ctxs=128,\n",
    "    out_batch_size = 256,\n",
    "    refresh_batch_size = 256,\n",
    "    device=device,\n",
    "    dtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.connections = connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "(initial_acts, input_acts, target_acts, layernorm_scales) = next(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = suite.pruned_forward_train(initial_acts, input_acts, layernorm_scales, n_threshold=10, n_random=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.1875e+00,  1.8500e+01,  4.3125e+00,  3.9219e+00,  5.2500e+00,\n",
       "         3.5000e+00,  3.4375e+00,  1.6406e+00, -1.5625e-01,  1.9062e+00,\n",
       "         2.0469e+00,  9.6875e-01,  4.3750e-01,  5.3125e-01,  3.5781e+00,\n",
       "        -4.2188e-01,  1.2812e+00,  1.2969e+00, -8.7500e-01,  1.1562e+00,\n",
       "        -1.8750e-01,  1.6250e+00, -5.7812e-01,  7.1094e-01, -3.2812e-01,\n",
       "         5.9375e-01,  5.6250e-01,  7.5000e-01, -8.2031e-01, -9.3750e-01,\n",
       "         1.5938e+00,  3.1250e-02, -9.3750e-02, -3.1250e-01, -5.9375e-01,\n",
       "         7.6562e-01,  1.4844e+00,  1.5625e-02, -2.2461e-01,  6.2500e-01,\n",
       "         5.2344e-01,  5.4688e-01, -6.2500e-01, -2.1484e-01,  1.4922e+00,\n",
       "        -9.4727e-02,  6.2500e-02,  1.3281e-01,  3.3594e-01, -7.6562e-01,\n",
       "        -2.4688e+00,  7.8125e-03, -3.7500e-01,  3.5938e-01,  8.0469e-01,\n",
       "        -5.4688e-01, -3.1250e-01, -6.5625e-01,  7.8125e-01,  2.6562e-01,\n",
       "        -8.4375e-01, -2.0312e-01,  2.2969e+00,  9.0625e-01,  2.2344e+00,\n",
       "        -5.6250e-01, -4.4531e-01, -1.8750e-01, -7.3438e-01,  1.3438e+00,\n",
       "         1.2891e+00,  9.3750e-01,  1.5781e+00, -5.4688e-01,  6.7969e-01,\n",
       "         2.4219e-01, -1.5234e+00,  7.6562e-01, -5.7031e-01,  4.6875e-01,\n",
       "        -5.9375e-01,  3.8281e-01, -3.5156e-02, -4.5117e-01,  6.9531e-01,\n",
       "         2.3438e-01,  1.0547e+00,  8.6328e-01,  4.4141e-01,  1.1250e+00,\n",
       "        -1.5625e-02, -9.2188e-01,  8.7500e-01, -5.7031e-01,  8.1250e-01,\n",
       "         1.2188e+00,  6.2500e-01, -6.2500e-02,  3.5156e-01,  2.1484e-01,\n",
       "        -1.7500e+00,  3.6719e-01, -6.8750e-01, -3.9844e-01,  2.3828e-01,\n",
       "         0.0000e+00, -2.5000e-01,  1.2188e+00, -7.0703e-01, -1.5625e+00,\n",
       "         4.0625e-01, -9.0625e-01,  1.1562e+00, -1.1797e+00,  1.3359e+00,\n",
       "         6.0156e-01,  2.5781e-01, -2.1875e-01, -2.7344e-02,  4.0625e-01,\n",
       "         3.1250e-02, -6.3281e-01,  6.7188e-01,  6.2500e-02,  4.3750e-01,\n",
       "        -4.0625e-01, -1.0000e+00,  4.6875e-02], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['mlp_0']['topk'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.1875e+00,  1.8500e+01,  4.3125e+00,  3.9219e+00,  5.2500e+00,\n",
       "         3.5000e+00,  3.4375e+00,  1.6406e+00, -1.5625e-01,  1.9062e+00,\n",
       "         2.0469e+00,  9.6875e-01,  4.3750e-01,  5.3125e-01,  3.5781e+00,\n",
       "        -4.2188e-01,  1.2812e+00,  1.2969e+00, -8.7500e-01,  1.1562e+00,\n",
       "        -1.8750e-01,  1.6250e+00, -5.7812e-01,  7.1094e-01, -3.2812e-01,\n",
       "         5.9375e-01,  5.6250e-01,  7.5000e-01, -8.2031e-01, -9.3750e-01,\n",
       "         1.5938e+00,  3.1250e-02, -9.3750e-02, -3.1250e-01, -5.9375e-01,\n",
       "         7.6562e-01,  1.4844e+00,  1.5625e-02, -2.2461e-01,  6.2500e-01,\n",
       "         5.2344e-01,  5.4688e-01, -6.2500e-01, -2.1484e-01,  1.4922e+00,\n",
       "        -9.4727e-02,  6.2500e-02,  1.3281e-01,  3.3594e-01, -7.6562e-01,\n",
       "        -2.4688e+00,  7.8125e-03, -3.7500e-01,  3.5938e-01,  8.0469e-01,\n",
       "        -5.4688e-01, -3.1250e-01, -6.5625e-01,  7.8125e-01,  2.6562e-01,\n",
       "        -8.4375e-01, -2.0312e-01,  2.2969e+00,  9.0625e-01,  2.2344e+00,\n",
       "        -5.6250e-01, -4.4531e-01, -1.8750e-01, -7.3438e-01,  1.3438e+00,\n",
       "         1.2891e+00,  9.3750e-01,  1.5781e+00, -5.4688e-01,  6.7969e-01,\n",
       "         2.4219e-01, -1.5234e+00,  7.6562e-01, -5.7031e-01,  4.6875e-01,\n",
       "        -5.9375e-01,  3.8281e-01, -3.5156e-02, -4.5117e-01,  6.9531e-01,\n",
       "         2.3438e-01,  1.0547e+00,  8.6328e-01,  4.4141e-01,  1.1250e+00,\n",
       "        -1.5625e-02, -9.2188e-01,  8.7500e-01, -5.7031e-01,  8.1250e-01,\n",
       "         1.2188e+00,  6.2500e-01, -6.2500e-02,  3.5156e-01,  2.1484e-01,\n",
       "        -1.7500e+00,  3.6719e-01, -6.8750e-01, -3.9844e-01,  2.3828e-01,\n",
       "         0.0000e+00, -2.5000e-01,  1.2188e+00, -7.0703e-01, -1.5625e+00,\n",
       "         4.0625e-01, -9.0625e-01,  1.1562e+00, -1.1797e+00,  1.3359e+00,\n",
       "         6.0156e-01,  2.5781e-01, -2.1875e-01, -2.7344e-02,  4.0625e-01,\n",
       "         3.1250e-02, -6.3281e-01,  6.7188e-01,  6.2500e-02,  4.3750e-01,\n",
       "        -4.0625e-01, -1.0000e+00,  4.6875e-02], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['mlp_0']['topk'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = suite.aes['mlp_0']\n",
    "x = t.randn(1, 768, device=device, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ae.encode(x, n_threshold=10, return_topk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31.8750, 27.0000, 24.3750, 23.2500, 22.2500, 21.1250, 19.2500, 19.1250,\n",
       "         19.1250, 18.8750, 18.5000, 18.5000, 18.2500, 18.2500, 17.8750, 17.8750,\n",
       "         17.6250, 17.3750, 17.2500, 17.0000, 17.0000, 16.8750, 16.8750, 16.7500,\n",
       "         16.6250, 16.6250, 16.6250, 16.6250, 16.5000, 16.3750, 16.2500, 16.2500,\n",
       "         16.2500, 16.1250, 16.0000, 15.9375, 15.9375, 15.8750, 15.8125, 15.7500,\n",
       "         15.7500, 15.6875, 15.6875, 15.6250, 15.6250, 15.4375, 15.2500, 15.1875,\n",
       "         15.1875, 15.1875, 15.1250, 15.0625, 15.0625, 15.0625, 14.9375, 14.9375,\n",
       "         14.8125, 14.8125, 14.6250, 14.4375, 14.3750, 14.3125, 14.2500, 14.1250,\n",
       "         14.0000, 14.0000, 13.9375, 13.9375, 13.9375, 13.8750, 13.8750, 13.8750,\n",
       "         13.6875, 13.6875, 13.6250, 13.5625, 13.5000, 13.4375, 13.3750, 13.3125,\n",
       "         13.3125, 13.3125, 13.2500, 13.2500, 13.1250, 13.0625, 13.0625, 13.0000,\n",
       "         12.9375, 12.9375, 12.9375, 12.9375, 12.8750, 12.8750, 12.8750, 12.8125,\n",
       "         12.8125, 12.8125, 12.8125, 12.8125, 12.7500, 12.7500, 12.6875, 12.6875,\n",
       "         12.6875, 12.6250, 12.5625, 12.5625, 12.5000, 12.5000, 12.5000, 12.5000,\n",
       "         12.4375, 12.4375, 12.3750, 12.3750, 12.3750, 12.3125, 12.3125, 12.2500,\n",
       "         12.1875, 12.1875, 12.1875, 12.1875, 12.1250, 12.1250, 12.1250, 12.1250]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31.8750, 27.0000, 24.3750, 23.2500, 22.2500, 21.1250, 19.2500, 19.1250,\n",
       "         19.1250, 18.8750, 18.5000, 18.5000, 18.2500, 18.2500, 17.8750, 17.8750,\n",
       "         17.6250, 17.3750, 17.2500, 17.0000, 17.0000, 16.8750, 16.8750, 16.7500,\n",
       "         16.6250, 16.6250, 16.6250, 16.6250, 16.5000, 16.3750, 16.2500, 16.2500,\n",
       "         16.2500, 16.1250, 16.0000, 15.9375, 15.9375, 15.8750, 15.8125, 15.7500,\n",
       "         15.7500, 15.6875, 15.6875, 15.6250, 15.6250, 15.4375, 15.2500, 15.1875,\n",
       "         15.1875, 15.1875, 15.1250, 15.0625, 15.0625, 15.0625, 14.9375, 14.9375,\n",
       "         14.8125, 14.8125, 14.6250, 14.4375, 14.3750, 14.3125, 14.2500, 14.1250,\n",
       "         14.0000, 14.0000, 13.9375, 13.9375, 13.9375, 13.8750, 13.8750, 13.8750,\n",
       "         13.6875, 13.6875, 13.6250, 13.5625, 13.5000, 13.4375, 13.3750, 13.3125,\n",
       "         13.3125, 13.3125, 13.2500, 13.2500, 13.1250, 13.0625, 13.0625, 13.0000,\n",
       "         12.9375, 12.9375, 12.9375, 12.9375, 12.8750, 12.8750, 12.8750, 12.8125,\n",
       "         12.8125, 12.8125, 12.8125, 12.8125, 12.7500, 12.7500, 12.6875, 12.6875,\n",
       "         12.6875, 12.6250, 12.5625, 12.5625, 12.5000, 12.5000, 12.5000, 12.5000,\n",
       "         12.4375, 12.4375, 12.3750, 12.3750, 12.3750, 12.3125, 12.3125, 12.2500,\n",
       "         12.1875, 12.1875, 12.1875, 12.1875, 12.1250, 12.1250, 12.1250, 12.1250,\n",
       "         12.0625, 12.0625, 12.0625, 12.0625, 11.8750, 11.8750, 11.8750, 11.8750,\n",
       "         11.8750, 11.8750]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
