{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from buffer import AllActivationBuffer\n",
    "from trainers.scae import SCAESuite\n",
    "from utils import load_model_with_folded_ln2, load_iterable_dataset\n",
    "\n",
    "DTYPE = t.bfloat16\n",
    "device = \"cuda:0\" if t.cuda.is_available() else \"cpu\"\n",
    "model = load_model_with_folded_ln2(\"gpt2\", device=device, torch_dtype=DTYPE)\n",
    "\n",
    "data = load_iterable_dataset('Skylion007/openwebtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "expansion = 16\n",
    "k = 128\n",
    "\n",
    "num_features = model.config.n_embd * expansion\n",
    "n_layer = model.config.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8356ba5a9e842b8a8d58a6e1e650643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_0.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/notebooks/../trainers/scae.py:589: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = t.load(weights_path, map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a30c2f375746aabd3cd4c37a1b29ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_0.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d8c34680d64b3abbe1f06eea8a63c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_1.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535d8c029a87430ba689675ab0915375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_1.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cc72e831ea4a42addd089b44f5a4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_2.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2f0f85b22c447db9bd18a23d6e2673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_2.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df4300e3eb34d52b29535953fe9b11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_3.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1accd8899b4d48be03bfa31e1e4ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_3.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7feed0654094e5eb4aa700d8008f6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_4.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da650bc4e43a4abd946221bac9b6762e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_4.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08586959f7c4d439714e91d3b9de889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_5.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2954848781c4b489f5448e405d11b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_5.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c703b093d5f4ae0a85c633a557ed858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_6.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91b0bfb4898456a9320f5ae561b6976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_6.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bdf22371484452823bd6efe67e5ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_7.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b9970029ea4662af062d2891fa5aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_7.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57e266b88ce40c296ae456e3979c3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_8.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b86cd31c2af4d3393189ebadb5b230c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_8.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d166b0cc27e42e39e529f0b630f453d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_9.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dcc54444264ebc93a12dfa82748f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_9.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e5906863fb4db5ad7e07c57007d67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_10.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc15bd6c7314d85a8fdce469c0fd36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_10.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f06e5e37700459291ae5202a4d3408d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_attn_11.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266b24b6d13241a48b56bf1703d1fa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ae_mlp_11.pt:   0%|          | 0.00/75.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_configs = {}\n",
    "connections = defaultdict(dict)\n",
    "\n",
    "for down_layer in range(n_layer):\n",
    "    for module in ['attn', 'mlp']:\n",
    "        down_name = f'{module}_{down_layer}'\n",
    "        pretrained_configs[f'{module}_{down_layer}'] = {\n",
    "            'repo_id': 'jacobcd52/scae', \n",
    "            'filename': f'ae_{module}_{down_layer}.pt',\n",
    "            'k' : k,\n",
    "            }\n",
    "        \n",
    "        # Use random connections for testing\n",
    "        if module=='mlp':\n",
    "            for up_layer in range(down_layer+1):\n",
    "                up_name = f'{module}_{up_layer}'\n",
    "                connections[down_name][up_name] = t.randint(0, num_features, (num_features, C), dtype=t.long)\n",
    "\n",
    "suite = SCAESuite.from_pretrained(\n",
    "    pretrained_configs, \n",
    "    connections=connections,\n",
    "    dtype=DTYPE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_submodule = model.transformer.h[0]\n",
    "\n",
    "layernorm_submodules = {}\n",
    "submodules = {}\n",
    "for layer in range(n_layer):\n",
    "    submodules[f\"mlp_{layer}\"] = (model.transformer.h[layer].mlp, \"in_and_out\")\n",
    "    submodules[f\"attn_{layer}\"] = (model.transformer.h[layer].attn, \"out\")\n",
    "\n",
    "    layernorm_submodules[f\"mlp_{layer}\"] = model.transformer.h[layer].ln_2\n",
    "\n",
    "buffer = AllActivationBuffer(\n",
    "    data=data,\n",
    "    model=model,\n",
    "    submodules=submodules,\n",
    "    initial_submodule=initial_submodule,\n",
    "    layernorm_submodules=layernorm_submodules,\n",
    "    d_submodule=model.config.n_embd,\n",
    "    n_ctxs=128,\n",
    "    out_batch_size = 2,\n",
    "    refresh_batch_size = 2,\n",
    "    device=device,\n",
    "    dtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(\n",
    "        suite, \n",
    "        buffer, \n",
    "        n_batches=10, \n",
    "        ce_batch_size=32,\n",
    "        use_sparse_connections=False\n",
    "        ):\n",
    "    '''Simple function to run evaluation on several batches, and return the average metrics'''\n",
    "    \n",
    "    varexp_metrics = {name : {} for name in buffer.submodules.keys()}\n",
    "    ce_metrics = {name : {} for name in buffer.submodules.keys()}\n",
    "\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        # get varexp metrics\n",
    "        initial_acts, input_acts, output_acts, layernorm_scales = next(buffer)\n",
    "        batch_varexp_metrics = suite.evaluate_varexp_batch(\n",
    "            initial_acts,\n",
    "            input_acts, \n",
    "            output_acts,\n",
    "            layernorm_scales,\n",
    "            use_sparse_connections=use_sparse_connections\n",
    "            )\n",
    "\n",
    "        # get CE metrics\n",
    "        b = buffer.refresh_batch_size\n",
    "        buffer.refresh_batch_size = ce_batch_size\n",
    "        tokens = buffer.token_batch()\n",
    "        batch_ce_metrics = suite.evaluate_ce_batch(\n",
    "            model, \n",
    "            tokens, \n",
    "            initial_submodule,\n",
    "            submodules,\n",
    "            layernorm_submodules,\n",
    "            use_sparse_connections=use_sparse_connections\n",
    "            )\n",
    "        buffer.refresh_batch_size = b\n",
    "\n",
    "        for name in ce_metrics.keys():\n",
    "            for metric in batch_ce_metrics[name].keys():\n",
    "                ce_metrics[name][metric] = ce_metrics[name].get(metric, 0) + batch_ce_metrics[name].get(metric, 0) / n_batches\n",
    "            for metric in batch_varexp_metrics[name].keys():\n",
    "                varexp_metrics[name][metric] = varexp_metrics[name].get(metric, 0) + batch_varexp_metrics[name].get(metric, 0) / n_batches\n",
    "           \n",
    "    return varexp_metrics, ce_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "varexp_metrics, ce_metrics = run_evaluation(\n",
    "    suite, \n",
    "    buffer, \n",
    "    n_batches=10, \n",
    "    ce_batch_size=2,\n",
    "    use_sparse_connections=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean loss = 3.391\n",
      "\n",
      "Module  CE increase  CE expl FVU\n",
      "mlp_0   2.119        51%     162%\n",
      "mlp_1   2.544        -1838%     255%\n",
      "mlp_2   2.597        -5706%     49649%\n",
      "mlp_3   5.634        -13572%     7220%\n",
      "mlp_4   5.716        -13395%     4721%\n",
      "mlp_5   6.272        -11866%     2631%\n",
      "mlp_6   5.428        -7154%     1641%\n",
      "mlp_7   4.650        -7210%     1071%\n",
      "mlp_8   4.384        -6736%     716%\n",
      "mlp_9   3.950        -5369%     562%\n",
      "mlp_10   3.416        -2698%     296%\n",
      "mlp_11   3.825        -1902%     167%\n",
      "\n",
      "attn_0   -0.000        100%     1%\n",
      "attn_1   -0.002        77%     2%\n",
      "attn_2   0.005        70%     6%\n",
      "attn_3   -0.003        112%     7%\n",
      "attn_4   0.000        96%     5%\n",
      "attn_5   0.000        71%     6%\n",
      "attn_6   0.009        58%     7%\n",
      "attn_7   -0.006        117%     6%\n",
      "attn_8   0.003        88%     5%\n",
      "attn_9   0.003        86%     6%\n",
      "attn_10   0.005        85%     5%\n",
      "attn_11   0.000        100%     0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clean loss = {ce_metrics['mlp_0']['loss_original']:.3f}\\n\")\n",
    "\n",
    "print(\"Module  CE increase  CE expl FVU\")\n",
    "for name in [k for k in ce_metrics.keys() if 'mlp' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}        {ce_metrics[name]['frac_recovered']*100:.0f}%     {varexp_metrics[name]['FVU']*100:.0f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "for name in [k for k in ce_metrics.keys() if 'attn' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}        {ce_metrics[name]['frac_recovered']*100:.0f}%     {varexp_metrics[name]['FVU']*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
