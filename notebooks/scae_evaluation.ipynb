{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from buffer import AllActivationBuffer\n",
    "from trainers.scae import SCAESuite\n",
    "from utils import load_model_with_folded_ln2, load_iterable_dataset\n",
    "\n",
    "DTYPE = t.bfloat16\n",
    "device = \"cuda:0\" if t.cuda.is_available() else \"cpu\"\n",
    "t.set_grad_enabled(False)\n",
    "t.manual_seed(42)\n",
    "\n",
    "model = load_model_with_folded_ln2(\"gpt2\", device=device, torch_dtype=DTYPE)\n",
    "data = load_iterable_dataset('Skylion007/openwebtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansion = 16\n",
    "k = 128\n",
    "\n",
    "num_features = model.config.n_embd * expansion\n",
    "n_layer = model.config.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/notebooks/../trainers/scae.py:628: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = t.load(checkpoint_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "suite = SCAESuite.from_pretrained(\n",
    "    'jacobcd52/gpt2_suite_folded_ln',\n",
    "    device=device,\n",
    "    dtype=DTYPE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "initial_submodule = model.transformer.h[0]\n",
    "layernorm_submodules = {}\n",
    "submodules = {}\n",
    "for layer in range(n_layer):\n",
    "    submodules[f\"mlp_{layer}\"] = (model.transformer.h[layer].mlp, \"in_and_out\")\n",
    "    submodules[f\"attn_{layer}\"] = (model.transformer.h[layer].attn, \"out\")\n",
    "\n",
    "    layernorm_submodules[f\"mlp_{layer}\"] = model.transformer.h[layer].ln_2\n",
    "\n",
    "buffer = AllActivationBuffer(\n",
    "    data=data,\n",
    "    model=model,\n",
    "    submodules=submodules,\n",
    "    initial_submodule=initial_submodule,\n",
    "    layernorm_submodules=layernorm_submodules,\n",
    "    d_submodule=model.config.n_embd,\n",
    "    n_ctxs=128,\n",
    "    out_batch_size = 32,\n",
    "    refresh_batch_size = 256,\n",
    "    device=device,\n",
    "    dtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load connections from top_connections.pkl\n",
    "# USE PICKLE\n",
    "import pickle\n",
    "with open('/root/dictionary_learning/top_connections.pkl', 'rb') as f:\n",
    "    top_connections = pickle.load(f)\n",
    "suite.connections = top_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_conns = t.arange(0, num_features, device=device, dtype=t.int64).unsqueeze(0).expand(num_features, num_features)\n",
    "# connections = {}\n",
    "# for down_layer in range(n_layer):\n",
    "#     connections[f\"mlp_{down_layer}\"] = {}\n",
    "#     for up_layer in range(down_layer):\n",
    "#         connections[f\"mlp_{down_layer}\"][f\"attn_{up_layer}\"] = all_conns\n",
    "#         connections[f\"mlp_{down_layer}\"][f\"mlp_{up_layer}\"] = all_conns \n",
    "#     connections[f\"mlp_{down_layer}\"][f\"attn_{down_layer}\"] = all_conns\n",
    "# suite.connections = connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(\n",
    "        suite, \n",
    "        buffer, \n",
    "        n_batches=10, \n",
    "        ce_batch_size=32,\n",
    "        use_sparse_connections=False\n",
    "        ):\n",
    "    '''Simple function to run evaluation on several batches, and return the average metrics'''\n",
    "    \n",
    "    varexp_metrics = {name : {} for name in buffer.submodules.keys()}\n",
    "    ce_metrics = {name : {} for name in buffer.submodules.keys()}\n",
    "\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        # get varexp metrics\n",
    "        initial_acts, input_acts, output_acts, layernorm_scales = next(buffer)\n",
    "        batch_varexp_metrics = suite.evaluate_varexp_batch(\n",
    "            initial_acts,\n",
    "            input_acts, \n",
    "            output_acts,\n",
    "            layernorm_scales,\n",
    "            use_sparse_connections=use_sparse_connections\n",
    "            )\n",
    "\n",
    "        # # get CE metrics\n",
    "        # b = buffer.refresh_batch_size\n",
    "        # buffer.refresh_batch_size = ce_batch_size\n",
    "        # tokens = buffer.token_batch()\n",
    "        # batch_ce_metrics = suite.evaluate_ce_batch(\n",
    "        #     model, \n",
    "        #     tokens, \n",
    "        #     initial_submodule,\n",
    "        #     submodules,\n",
    "        #     layernorm_submodules,\n",
    "        #     use_sparse_connections=use_sparse_connections\n",
    "        #     )\n",
    "        # buffer.refresh_batch_size = b\n",
    "\n",
    "        for name in ce_metrics.keys():\n",
    "            # for metric in batch_ce_metrics[name].keys():\n",
    "            #     ce_metrics[name][metric] = ce_metrics[name].get(metric, 0) + batch_ce_metrics[name].get(metric, 0) / n_batches\n",
    "            for metric in batch_varexp_metrics[name].keys():\n",
    "                varexp_metrics[name][metric] = varexp_metrics[name].get(metric, 0) + batch_varexp_metrics[name].get(metric, 0) / n_batches\n",
    "           \n",
    "    return varexp_metrics, ce_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "varexp_metrics, ce_metrics = run_evaluation(\n",
    "    suite, \n",
    "    buffer, \n",
    "    n_batches=2, \n",
    "    ce_batch_size=1,\n",
    "    use_sparse_connections=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ce_metrics.keys():\n",
    "    ce_metrics[name]['loss_reconstructed'] = 1\n",
    "    ce_metrics[name]['loss_original'] = 1\n",
    "    ce_metrics[name]['frac_recovered'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.484e+03, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.070e+03, 0.000e+00, 0.000e+00, 1.300e+01, 3.000e+00,\n",
       "        4.000e+00, 9.000e+00, 4.000e+00, 1.500e+01, 1.100e+01, 1.100e+01,\n",
       "        1.300e+01, 1.500e+01, 2.700e+01, 4.200e+01, 9.400e+01, 1.450e+02,\n",
       "        1.680e+02, 1.870e+02, 1.250e+02, 4.800e+01, 3.800e+01, 3.400e+01,\n",
       "        2.100e+01, 2.400e+01, 3.700e+01, 4.500e+01, 4.500e+01, 7.700e+01,\n",
       "        1.110e+02, 9.800e+01, 1.060e+02, 1.010e+02, 8.000e+01, 6.100e+01,\n",
       "        5.000e+01, 5.000e+01, 4.700e+01, 1.020e+02, 5.400e+01, 7.300e+01,\n",
       "        8.100e+01, 8.600e+01, 6.400e+01, 6.900e+01, 6.500e+01, 6.700e+01,\n",
       "        5.400e+01, 8.500e+01, 6.100e+01, 6.700e+01, 7.000e+01, 7.800e+01,\n",
       "        6.100e+01, 8.200e+01, 6.100e+01, 1.150e+02, 5.900e+01, 5.300e+01,\n",
       "        5.400e+01, 5.300e+01, 5.600e+01, 6.100e+01, 5.700e+01, 5.100e+01,\n",
       "        5.700e+01, 4.800e+01, 4.600e+01, 4.300e+01, 4.200e+01, 6.400e+01,\n",
       "        5.000e+01, 4.100e+01, 4.000e+01, 2.505e+03]),\n",
       " array([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,\n",
       "         55.,  60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105.,\n",
       "        110., 115., 120., 125., 130., 135., 140., 145., 150., 155., 160.,\n",
       "        165., 170., 175., 180., 185., 190., 195., 200., 205., 210., 215.,\n",
       "        220., 225., 230., 235., 240., 245., 250., 255., 260., 265., 270.,\n",
       "        275., 280., 285., 290., 295., 300., 305., 310., 315., 320., 325.,\n",
       "        330., 335., 340., 345., 350., 355., 360., 365., 370., 375., 380.,\n",
       "        385., 390., 395., 400., 405., 410., 415., 420., 425., 430., 435.,\n",
       "        440., 445., 450., 455., 460., 465., 470., 475., 480., 485., 490.,\n",
       "        495., 500.]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_conns = (top_connections['mlp_0']['attn_0'] != -1).float().sum(-1).detach().cpu()\n",
    "plt.hist(num_conns, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean loss = 1.000\n",
      "\n",
      "Module  CE increase  CE expl FVU\n",
      "mlp_0   0.000        100%     12%\n",
      "mlp_1   0.000        100%     49%\n",
      "mlp_2   0.000        100%     68%\n",
      "mlp_3   0.000        100%     69%\n",
      "mlp_4   0.000        100%     69%\n",
      "mlp_5   0.000        100%     91%\n",
      "mlp_6   0.000        100%     82%\n",
      "mlp_7   0.000        100%     95%\n",
      "mlp_8   0.000        100%     90%\n",
      "mlp_9   0.000        100%     123%\n",
      "mlp_10   0.000        100%     307%\n",
      "mlp_11   0.000        100%     451%\n",
      "\n",
      "attn_0   0.000        100%     1%\n",
      "attn_1   0.000        100%     3%\n",
      "attn_2   0.000        100%     4%\n",
      "attn_3   0.000        100%     6%\n",
      "attn_4   0.000        100%     7%\n",
      "attn_5   0.000        100%     7%\n",
      "attn_6   0.000        100%     8%\n",
      "attn_7   0.000        100%     6%\n",
      "attn_8   0.000        100%     8%\n",
      "attn_9   0.000        100%     7%\n",
      "attn_10   0.000        100%     5%\n",
      "attn_11   0.000        100%     0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clean loss = {ce_metrics['mlp_0']['loss_original']:.3f}\\n\")\n",
    "\n",
    "print(\"Module  CE increase  CE expl FVU\")\n",
    "for name in [k for k in ce_metrics.keys() if 'mlp' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}        {ce_metrics[name]['frac_recovered']*100:.0f}%     {varexp_metrics[name]['FVU']*100:.0f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "for name in [k for k in ce_metrics.keys() if 'attn' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}        {ce_metrics[name]['frac_recovered']*100:.0f}%     {varexp_metrics[name]['FVU']*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean loss = 1.000\n",
      "\n",
      "Module  CE increase  CE expl FVU\n",
      "mlp_0   0.000        100%     4%\n",
      "mlp_1   0.000        100%     11%\n",
      "mlp_2   0.000        100%     19%\n",
      "mlp_3   0.000        100%     12%\n",
      "mlp_4   0.000        100%     15%\n",
      "mlp_5   0.000        100%     16%\n",
      "mlp_6   0.000        100%     17%\n",
      "mlp_7   0.000        100%     17%\n",
      "mlp_8   0.000        100%     17%\n",
      "mlp_9   0.000        100%     15%\n",
      "mlp_10   0.000        100%     11%\n",
      "mlp_11   0.000        100%     8%\n",
      "\n",
      "attn_0   0.000        100%     1%\n",
      "attn_1   0.000        100%     3%\n",
      "attn_2   0.000        100%     4%\n",
      "attn_3   0.000        100%     6%\n",
      "attn_4   0.000        100%     8%\n",
      "attn_5   0.000        100%     7%\n",
      "attn_6   0.000        100%     8%\n",
      "attn_7   0.000        100%     7%\n",
      "attn_8   0.000        100%     8%\n",
      "attn_9   0.000        100%     7%\n",
      "attn_10   0.000        100%     6%\n",
      "attn_11   0.000        100%     1%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clean loss = {ce_metrics['mlp_0']['loss_original']:.3f}\\n\")\n",
    "\n",
    "print(\"Module  CE increase  CE expl FVU\")\n",
    "for name in [k for k in ce_metrics.keys() if 'mlp' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}        {ce_metrics[name]['frac_recovered']*100:.0f}%     {varexp_metrics[name]['FVU']*100:.0f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "for name in [k for k in ce_metrics.keys() if 'attn' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}        {ce_metrics[name]['frac_recovered']*100:.0f}%     {varexp_metrics[name]['FVU']*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlp_0': tensor([[   -1,    -1,    -1,  ...,    -1,    -1,    -1],\n",
       "         [  250,    -1, 11139,  ...,    -1,  7932,    -1],\n",
       "         [   -1,    -1,    -1,  ...,    -1,    -1,    -1],\n",
       "         ...,\n",
       "         [  250,    -1, 11139,  ..., 12242,    -1,    -1],\n",
       "         [  250,    -1,    -1,  ..., 11132,    -1,    -1],\n",
       "         [   -1,    -1,    -1,  ...,    -1,    -1,    -1]], device='cuda:0'),\n",
       " 'mlp_1': tensor([[   -1,    -1,    -1,  ...,    -1,    -1,    -1],\n",
       "         [   -1,  3208,    -1,  ...,    -1,    -1,  2056],\n",
       "         [   -1,    -1,    -1,  ...,    -1,    -1,    -1],\n",
       "         ...,\n",
       "         [   -1,  3208,    -1,  ...,    -1,  3180,    -1],\n",
       "         [   -1,    -1, 11580,  ...,    -1,    -1,    -1],\n",
       "         [ 3208,    -1,    -1,  ...,    -1,    -1,    -1]], device='cuda:0'),\n",
       " 'attn_0': tensor([[   -1,    -1,    -1,  ...,    -1,    -1,    -1],\n",
       "         [   -1,    -1,    -1,  ...,    -1,    -1,    -1],\n",
       "         [   -1,    -1,    -1,  ...,    -1,    -1,    -1],\n",
       "         ...,\n",
       "         [   -1,    -1,    -1,  ...,    -1,    -1,  8040],\n",
       "         [   -1,  7999,    -1,  ...,    -1, 10984,    -1],\n",
       "         [   -1,  7999,  6528,  ...,    -1,    -1,    -1]], device='cuda:0'),\n",
       " 'attn_1': tensor([[  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         ...,\n",
       "         [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,  ...,   -1,   -1, 9584],\n",
       "         [  -1,   -1,   -1,  ...,   -1, 1383, 5653]], device='cuda:0'),\n",
       " 'attn_2': tensor([[  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,  ...,  321,   -1,   -1],\n",
       "         [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         ...,\n",
       "         [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,  ...,   -1,   -1,   -1],\n",
       "         [  -1,   -1,   -1,  ..., 6794,   -1,   -1]], device='cuda:0')}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_connections['mlp_10']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
