{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import IPython\n",
    "# IPython.get_ipython().run_line_magic('cd', '..')  # Go up one directory\n",
    "\n",
    "from buffer import AllActivationBuffer\n",
    "from trainers.top_k import TrainerSCAE, AutoEncoderTopK\n",
    "from training import trainSCAE\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "#\n",
    "device = \"cuda:0\" if t.cuda.is_available() else \"cpu\"\n",
    "model = LanguageModel(\"gpt2\", device_map=device, torch_dtype=t.bfloat16)\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'Skylion007/openwebtext', \n",
    "    split='train', \n",
    "    streaming=True,\n",
    "    trust_remote_code=True\n",
    "    )\n",
    "\n",
    "class CustomData():\n",
    "    def __init__(self, dataset):\n",
    "        self.data = iter(dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return next(self.data)['text']\n",
    "\n",
    "data = CustomData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "expansion = 16\n",
    "k = 64 # TODO\n",
    "\n",
    "num_features = model.config.n_embd * expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "n_layer = model.config.n_layer\n",
    "\n",
    "submodules = {}\n",
    "for layer in range(n_layer):\n",
    "    submodules[f\"mlp_{layer}\"] = (model.transformer.h[layer].mlp, \"in_and_out\")\n",
    "    submodules[f\"attn_{layer}\"] = (model.transformer.h[layer].attn, \"out\")\n",
    "\n",
    "\n",
    "buffer = AllActivationBuffer(\n",
    "    data=data,\n",
    "    model=model,\n",
    "    submodules=submodules,\n",
    "    d_submodule=model.config.n_embd, # output dimension of the model component\n",
    "    n_ctxs=128,  # you can set this higher or lower depending on your available memory\n",
    "    device=\"cuda\",\n",
    "    out_batch_size = 1024,\n",
    "    refresh_batch_size = 256,\n",
    "    dtype=t.bfloat16,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = {f\"mlp_{layer}\": t.randint(0, num_features, (num_features, C))\n",
    "                        for layer in range(model.config.n_layer)}\n",
    "\n",
    "# Get submodule names from the submodules dictionary\n",
    "submodule_names = list(submodules.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_info = {}\n",
    "for layer in range(model.config.n_layer):\n",
    "    for module in ['attn', 'mlp']:\n",
    "        pretrained_info[f'{module}_{layer}'] = {'repo_id': 'jacobcd52/scae', 'filename': f'ae_{module}_{layer}.pt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerSCAE(\n",
    "        activation_dims={name: model.config.n_embd for name in submodule_names},\n",
    "        dict_sizes={name: model.config.n_embd * expansion for name in submodule_names},\n",
    "        ks={name: k for name in submodule_names},\n",
    "        submodules=submodules,\n",
    "        important_features={},\n",
    "        pretrained_info=pretrained_info,\n",
    "        model_config=model.config,\n",
    "        auxk_alpha=0,\n",
    "        connection_sparsity_coeff=0,\n",
    "        use_sparse_connections=False,\n",
    "        seed=None,\n",
    "        device=\"cuda\",\n",
    "        wandb_name=\"SCAE\",\n",
    "        dtype=t.bfloat16,  # Add dtype parameter\n",
    ")\n",
    "\n",
    "#aa9a791c5e40fa7ab2f08d555ff72352c1cecaa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_acts, output_acts = next(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = buffer.token_batch()\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "varexp_metrics = trainer.evaluate_varexp(input_acts, output_acts, use_sparse_connections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== First Trace ===\n",
      "Inside trace - before saving:\n",
      "model.output type: <class 'nnsight.models.LanguageModel.LanguageModelProxy'>\n",
      "\n",
      "Saved full output\n",
      "\n",
      "Processing module mlp_0 with io in_and_out\n",
      "\n",
      "Processing module attn_0 with io out\n",
      "\n",
      "Processing module mlp_1 with io in_and_out\n",
      "\n",
      "Processing module attn_1 with io out\n",
      "\n",
      "Processing module mlp_2 with io in_and_out\n",
      "\n",
      "Processing module attn_2 with io out\n",
      "\n",
      "Processing module mlp_3 with io in_and_out\n",
      "\n",
      "Processing module attn_3 with io out\n",
      "\n",
      "Processing module mlp_4 with io in_and_out\n",
      "\n",
      "Processing module attn_4 with io out\n",
      "\n",
      "Processing module mlp_5 with io in_and_out\n",
      "\n",
      "Processing module attn_5 with io out\n",
      "\n",
      "Processing module mlp_6 with io in_and_out\n",
      "\n",
      "Processing module attn_6 with io out\n",
      "\n",
      "Processing module mlp_7 with io in_and_out\n",
      "\n",
      "Processing module attn_7 with io out\n",
      "\n",
      "Processing module mlp_8 with io in_and_out\n",
      "\n",
      "Processing module attn_8 with io out\n",
      "\n",
      "Processing module mlp_9 with io in_and_out\n",
      "\n",
      "Processing module attn_9 with io out\n",
      "\n",
      "Processing module mlp_10 with io in_and_out\n",
      "\n",
      "Processing module attn_10 with io out\n",
      "\n",
      "Processing module mlp_11 with io in_and_out\n",
      "\n",
      "Processing module attn_11 with io out\n",
      "\n",
      "Creating dummy reconstructions...\n",
      "\n",
      "=== Reconstruction Trace ===\n",
      "\n",
      "Processing mlp_0 with io=in_and_out\n",
      "Input x type: <class 'nnsight.models.LanguageModel.LanguageModelProxy'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Accessing value before it's been set.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ce_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_patched_ce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/trainers/top_k.py:733\u001b[0m, in \u001b[0;36mTrainerSCAE.evaluate_patched_ce\u001b[0;34m(self, model, text, max_len, use_sparse_connections, normalize_batch, device, tracer_args)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Reconstruction Trace ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    732\u001b[0m \u001b[38;5;66;03m# intervene with x_hat\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracer_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvoker_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvoker_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmodules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_hat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreconstructions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/nnsight/contexts/Tracer.py:102\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/nnsight/contexts/GraphBasedContext.py:215\u001b[0m, in \u001b[0;36mGraphBasedContext.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39malive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/dictionary_learning/trainers/top_k.py:778\u001b[0m, in \u001b[0;36mTrainerSCAE.evaluate_patched_ce\u001b[0;34m(self, model, text, max_len, use_sparse_connections, normalize_batch, device, tracer_args)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput x type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    777\u001b[0m x_saved \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m--> 778\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx_saved\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput value type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize_batch:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/nnsight/tracing/Proxy.py:50\u001b[0m, in \u001b[0;36mProxy.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Property to return the value of this proxy's node.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m        Any: The stored value of the proxy, populated during execution of the model.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/nnsight/tracing/Node.py:182\u001b[0m, in \u001b[0;36mNode.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Property to return the value of this node.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    ValueError: If the underlying ._value is inspect._empty (therefore never set or destroyed).\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing value before it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mValueError\u001b[0m: Accessing value before it's been set."
     ]
    }
   ],
   "source": [
    "ce_metrics = trainer.evaluate_patched_ce(model, tokens[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_0:    0.9140625\n",
      "attn_0:    0.953125\n",
      "mlp_1:    0.953125\n",
      "attn_1:    0.91015625\n",
      "mlp_2:    0.33203125\n",
      "attn_2:    0.89453125\n",
      "mlp_3:    0.8125\n",
      "attn_3:    0.8515625\n",
      "mlp_4:    0.765625\n",
      "attn_4:    0.8125\n",
      "mlp_5:    0.7109375\n",
      "attn_5:    0.828125\n",
      "mlp_6:    0.6875\n",
      "attn_6:    0.8046875\n",
      "mlp_7:    0.6796875\n",
      "attn_7:    0.828125\n",
      "mlp_8:    0.6796875\n",
      "attn_8:    0.8125\n",
      "mlp_9:    0.69921875\n",
      "attn_9:    0.8359375\n",
      "mlp_10:    0.7578125\n",
      "attn_10:    0.87109375\n",
      "mlp_11:    0.8671875\n",
      "attn_11:    0.83984375\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m varexp_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmodule_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrac_variance_explained\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mce_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmodule_metrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mce\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for key, value in varexp_metrics['submodule_metrics'].items():\n",
    "    print(f\"{key}:    {value['frac_variance_explained']}\")\n",
    "          \n",
    "for key, value in ce_metrics['submodule_metrics'].items():\n",
    "    print(f\"{key}:    {value['ce']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlp_0': tensor([[ 0.9336,  0.4648, -0.6992,  ...,  0.3457,  0.3145, -0.3203],\n",
       "         [ 0.3828,  0.2129, -0.2061,  ...,  0.9180,  0.0669, -0.0240],\n",
       "         [-0.8477, -0.4668, -1.0781,  ...,  0.1650, -0.3848, -0.3965],\n",
       "         ...,\n",
       "         [ 0.0388,  0.0469,  0.4355,  ...,  0.1631, -0.2295,  0.6328],\n",
       "         [ 1.0859,  0.7773, -1.1562,  ...,  1.1406, -1.3203, -0.1836],\n",
       "         [-1.0391, -0.3145, -0.8047,  ...,  0.1377,  0.3770, -0.6836]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_0': tensor([[ 1.8047e+00,  6.9531e-01,  3.2227e-01,  ..., -6.2988e-02,\n",
       "           3.1738e-02, -4.6631e-02],\n",
       "         [ 9.3842e-04,  2.2070e-01, -4.9219e-01,  ...,  6.8665e-03,\n",
       "           1.7212e-02, -1.7853e-03],\n",
       "         [ 1.0986e-01, -3.1641e-01, -8.3594e-01,  ...,  1.4099e-02,\n",
       "          -2.8931e-02, -2.3560e-02],\n",
       "         ...,\n",
       "         [ 8.5938e-01, -1.5527e-01,  8.6719e-01,  ..., -4.4678e-02,\n",
       "          -3.1738e-02, -6.3965e-02],\n",
       "         [-7.9688e-01, -7.0703e-01, -2.1777e-01,  ...,  5.4688e-02,\n",
       "          -1.8921e-02, -2.6733e-02],\n",
       "         [-8.9453e-01,  2.6978e-02, -1.8555e-01,  ..., -3.1128e-02,\n",
       "           3.8574e-02,  4.9316e-02]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_1': tensor([[-2.6855e-02, -1.6211e-01, -5.9375e-01,  ...,  3.9978e-03,\n",
       "           4.7070e-01,  3.2715e-02],\n",
       "         [ 6.7188e-01, -2.1680e-01,  3.0859e-01,  ...,  1.6211e-01,\n",
       "           2.4512e-01, -2.1458e-04],\n",
       "         [-8.8867e-02, -9.1309e-02,  1.3965e-01,  ...,  5.1172e-01,\n",
       "           1.2598e-01, -2.5586e-01],\n",
       "         ...,\n",
       "         [ 2.3047e-01,  2.6758e-01, -1.1475e-02,  ...,  2.8839e-03,\n",
       "           2.2461e-01,  1.7676e-01],\n",
       "         [ 1.0547e+00, -6.0547e-01, -6.8359e-01,  ...,  5.2734e-01,\n",
       "          -4.3945e-01,  6.8359e-01],\n",
       "         [-4.2578e-01, -2.6611e-02,  2.5586e-01,  ...,  4.4141e-01,\n",
       "           5.9375e-01, -4.4727e-01]], device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_1': tensor([[ 0.0747,  0.2949, -0.1943,  ..., -0.2949,  0.0894,  0.0830],\n",
       "         [ 0.2070,  0.2637, -0.5352,  ..., -0.2852,  0.1924, -0.0776],\n",
       "         [-0.2324,  0.1738, -0.2988,  ...,  0.1514, -0.0220,  0.0106],\n",
       "         ...,\n",
       "         [-0.3164, -0.0461,  0.1377,  ..., -0.1309,  0.0398, -0.1855],\n",
       "         [ 0.0383,  0.4492,  0.0991,  ..., -0.3730, -0.1226,  0.0889],\n",
       "         [-0.2256,  0.1592, -0.2949,  ..., -0.1846,  0.1348,  0.0289]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_2': tensor([[ 0.1367, -0.5625, -0.1572,  ..., -0.4414,  0.4492, -0.2139],\n",
       "         [-0.0349, -0.5039, -0.2617,  ..., -0.0845, -0.0991,  0.1465],\n",
       "         [ 0.4355, -0.3633,  0.1240,  ...,  0.7070, -0.5039,  0.0933],\n",
       "         ...,\n",
       "         [ 0.2158,  0.2158, -0.0469,  ..., -0.0928,  0.0869,  0.6484],\n",
       "         [-0.2754,  0.2314, -0.3613,  ...,  0.2275, -0.8516,  0.1143],\n",
       "         [-0.1553,  0.0923, -0.1895,  ...,  0.2598,  0.4609, -0.1709]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_2': tensor([[ 0.0264,  0.7031, -0.4863,  ...,  0.1187,  0.1299,  0.7617],\n",
       "         [ 0.0918,  0.5312, -0.5078,  ..., -0.0581,  0.6055, -0.6250],\n",
       "         [-0.5195,  0.1865, -0.0884,  ..., -0.1436,  0.2002,  0.1309],\n",
       "         ...,\n",
       "         [-0.2695, -0.4336, -0.1108,  ..., -0.1846, -0.0024, -0.3555],\n",
       "         [ 0.0947, -0.2773,  0.5781,  ..., -0.2080,  0.0255,  0.3848],\n",
       "         [-0.2383,  0.5312, -0.6172,  ..., -0.3320,  0.2578,  0.0608]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_3': tensor([[ 0.5234,  0.4199, -0.5039,  ...,  0.1138, -0.0752, -0.0271],\n",
       "         [ 0.1543,  0.3281,  0.4609,  ...,  0.2441, -0.5938,  0.8477],\n",
       "         [ 0.5469,  0.2871,  0.5156,  ...,  0.4434, -0.5078,  0.3438],\n",
       "         ...,\n",
       "         [-0.8789,  0.7266, -0.0410,  ...,  0.0491,  0.5469,  0.6172],\n",
       "         [-0.9297,  0.8281,  0.5508,  ...,  0.1465, -1.0234,  0.5273],\n",
       "         [-0.1484, -0.2354, -0.2275,  ..., -0.6914, -0.1270, -0.0479]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_3': tensor([[ 0.2070,  0.2754,  0.0077,  ..., -0.0698,  0.0019,  0.1631],\n",
       "         [ 0.1689, -0.1787, -0.6445,  ...,  0.3691,  0.1182, -0.4727],\n",
       "         [-0.3105,  0.1768, -0.2559,  ...,  0.3945,  0.3008,  0.3262],\n",
       "         ...,\n",
       "         [-0.3691,  0.1299, -0.0869,  ..., -0.3789, -0.3145, -0.0918],\n",
       "         [ 0.1270, -0.1289,  0.2285,  ...,  0.0083, -0.2949, -0.2598],\n",
       "         [-0.1025, -0.0786, -0.2246,  ..., -0.2021, -0.1543, -0.0835]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_4': tensor([[ 0.1318, -0.4316, -0.1475,  ...,  0.1445,  0.5195,  0.1396],\n",
       "         [ 0.2246, -0.1934, -0.2383,  ...,  0.3301,  0.0693,  0.8477],\n",
       "         [-0.1416,  0.7656, -0.2256,  ..., -0.5078,  0.7812,  0.5039],\n",
       "         ...,\n",
       "         [ 0.6328, -1.0312,  0.9180,  ..., -0.4727, -0.2021,  0.6250],\n",
       "         [-0.4727,  0.2178, -0.2168,  ..., -0.1719,  0.6992, -0.1279],\n",
       "         [-0.3672,  0.3438, -0.4805,  ..., -0.7422, -0.7422,  0.2754]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_4': tensor([[ 0.3809, -0.0635, -0.4824,  ...,  0.0151,  0.3066, -0.0762],\n",
       "         [ 0.2617, -0.9062, -0.2422,  ..., -0.0469, -0.0845, -0.0747],\n",
       "         [ 0.4355, -0.3887,  0.4922,  ..., -0.3613,  0.0115,  0.1660],\n",
       "         ...,\n",
       "         [-0.2988,  0.4551, -0.7031,  ..., -0.1982,  0.1089,  0.1533],\n",
       "         [-0.1445, -0.1025,  0.0591,  ..., -0.0762, -0.5820,  0.1758],\n",
       "         [ 0.0493,  0.2793, -0.4551,  ..., -0.2793,  0.3652,  0.7148]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_5': tensor([[ 0.2754,  0.2520, -0.5117,  ..., -0.5156, -0.4961, -0.1123],\n",
       "         [ 0.9062,  0.0530, -0.3555,  ...,  0.2471, -0.2432,  1.1641],\n",
       "         [-0.4395, -0.7617, -1.6719,  ..., -0.1807, -0.0747, -0.7578],\n",
       "         ...,\n",
       "         [-0.3555, -0.5039,  0.6523,  ..., -0.0967, -0.9570, -0.2598],\n",
       "         [-0.1689,  0.1367, -0.4668,  ...,  1.1875, -0.9297, -0.3984],\n",
       "         [ 0.3203,  0.9766, -0.9805,  ...,  0.1416,  0.9883, -0.1299]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_5': tensor([[ 0.0801,  0.0972, -0.1670,  ..., -0.1562, -0.5703,  0.0747],\n",
       "         [ 0.0498, -1.5000,  0.7539,  ...,  0.0752, -0.1768, -0.9023],\n",
       "         [-0.1416,  0.0684,  0.5234,  ..., -0.0046,  0.4688, -0.2217],\n",
       "         ...,\n",
       "         [-0.2559,  0.4160,  0.0064,  ..., -0.3535,  0.1494,  0.1201],\n",
       "         [-0.3418, -0.2539,  0.1318,  ...,  0.3926,  0.0603,  0.2969],\n",
       "         [ 0.3008, -0.0123, -0.5781,  ..., -0.0938,  0.4746, -0.0459]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_6': tensor([[ 0.1123, -0.3477,  0.5156,  ..., -0.2451,  0.7734, -0.3574],\n",
       "         [ 0.4902,  0.5469, -0.0625,  ..., -0.9336, -0.3281,  0.5625],\n",
       "         [-0.4277, -1.1562,  1.0703,  ...,  0.5977, -0.2002, -0.5039],\n",
       "         ...,\n",
       "         [-1.0312, -0.4004, -1.0000,  ...,  1.0234,  0.2871,  0.6172],\n",
       "         [ 0.4785,  0.6523, -0.5430,  ..., -0.6953,  0.5312, -0.3262],\n",
       "         [ 0.8867,  0.2617, -0.0520,  ..., -0.5664,  0.6562, -0.4844]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_6': tensor([[ 0.2578,  0.7539,  0.2930,  ..., -0.1953,  0.0110,  1.2578],\n",
       "         [-0.0996, -0.3574, -0.1680,  ..., -0.5469, -0.1865, -0.2168],\n",
       "         [ 0.1797, -0.2070,  0.1533,  ...,  0.2051, -0.0142,  0.4570],\n",
       "         ...,\n",
       "         [-0.1216,  0.4316,  0.0248,  ..., -0.0444, -0.1025, -0.2266],\n",
       "         [-0.3984, -0.0223, -0.2275,  ..., -0.3242, -0.6289, -0.1436],\n",
       "         [ 0.2207, -1.0078, -0.1426,  ..., -0.4121, -0.1729,  0.5352]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_7': tensor([[ 0.5703,  1.8828,  0.5000,  ...,  1.1719,  0.2432, -1.0703],\n",
       "         [-0.7188, -0.4941, -0.6758,  ..., -0.8047, -0.6367, -0.1338],\n",
       "         [ 1.0781, -0.8086, -0.3340,  ...,  0.1021,  1.1562, -0.4902],\n",
       "         ...,\n",
       "         [ 1.4141, -1.0625,  0.6250,  ..., -0.2832, -0.3965, -0.5664],\n",
       "         [ 0.1206, -0.0044,  0.6055,  ..., -0.3184,  0.4688,  0.2256],\n",
       "         [-0.3770, -0.2061,  0.6523,  ...,  1.1250, -0.9766, -0.3906]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_7': tensor([[ 0.5352,  0.6250,  0.2656,  ...,  0.2285,  0.3359,  1.8516],\n",
       "         [-1.0859, -0.0413, -0.9258,  ..., -0.5977, -0.4980,  0.6953],\n",
       "         [-0.3711,  0.1592,  0.6406,  ...,  0.2021,  0.3125,  0.2598],\n",
       "         ...,\n",
       "         [-0.5156,  0.2344, -0.5312,  ..., -0.1074, -0.2334, -0.4258],\n",
       "         [-0.3418, -0.1128,  0.0986,  ...,  0.1016, -0.1406, -0.2832],\n",
       "         [ 0.4043, -0.3301, -0.3613,  ...,  0.5078,  0.5039,  0.5430]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_8': tensor([[ 0.3301,  1.2031, -0.4199,  ...,  1.6328, -2.6094,  0.2910],\n",
       "         [ 0.5195, -0.3984,  0.9336,  ..., -0.7227,  0.9648, -2.2188],\n",
       "         [ 1.0938, -0.3535, -1.8984,  ..., -1.8906,  0.2637, -0.1895],\n",
       "         ...,\n",
       "         [ 1.8125, -0.5547,  0.1982,  ...,  0.0410,  1.3203, -1.7891],\n",
       "         [ 0.9023,  0.2266,  0.3086,  ...,  0.8398, -0.2119, -0.1670],\n",
       "         [-1.2578, -0.8320, -0.1235,  ..., -0.9844,  0.4551,  0.2441]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_8': tensor([[ 0.8867,  1.2422,  1.2109,  ..., -0.7188, -0.1074,  0.4609],\n",
       "         [ 0.3945, -0.1592,  0.1816,  ...,  0.2041,  0.5586, -0.7930],\n",
       "         [-0.5742, -0.4570, -0.0125,  ..., -0.5430, -0.4707,  1.3438],\n",
       "         ...,\n",
       "         [-0.3457,  0.8633, -0.1787,  ..., -0.5508, -0.2070, -0.1367],\n",
       "         [-0.0723, -0.4062,  0.0579,  ..., -0.0859, -0.4844, -0.4141],\n",
       "         [ 0.9258,  0.0811, -1.0859,  ...,  0.3457,  0.1074,  0.5156]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_9': tensor([[ 1.2188,  0.8047, -0.5312,  ..., -1.7969, -1.0078,  1.2969],\n",
       "         [-0.5195, -0.1201, -2.0469,  ..., -2.9844, -2.0156,  0.0143],\n",
       "         [-2.2656,  2.6250,  0.6992,  ...,  0.8672,  2.3906, -1.0078],\n",
       "         ...,\n",
       "         [-2.2344, -0.4863,  1.8359,  ..., -2.2969,  0.8516, -0.8359],\n",
       "         [-0.9102,  0.5625, -1.8047,  ...,  0.3652, -0.9141, -2.2969],\n",
       "         [ 1.8594,  0.2451, -1.2031,  ...,  0.2402,  0.0557, -0.0723]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_9': tensor([[ 0.6250,  0.0164, -0.1748,  ..., -0.4824,  0.4258,  0.3281],\n",
       "         [-2.2969,  0.4121, -1.4766,  ..., -2.3125,  0.7031,  0.5859],\n",
       "         [ 1.9609, -0.5508,  0.5703,  ...,  0.2520,  0.0688,  0.3770],\n",
       "         ...,\n",
       "         [-0.2266, -0.3906, -0.3320,  ...,  0.2451,  0.4688, -0.1602],\n",
       "         [-2.2812,  1.0625, -0.0806,  ..., -0.3535, -2.1406, -2.7969],\n",
       "         [ 0.4805, -0.2969, -0.6055,  ...,  0.2246, -0.0168,  0.7031]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_10': tensor([[ 1.6406,  2.7656,  0.9336,  ...,  0.1309, -2.4688, -0.2227],\n",
       "         [-1.5938, -4.9062, -2.6875,  ...,  0.9023, -1.7734, -2.2500],\n",
       "         [ 1.5469, -0.9453, -2.7969,  ...,  0.8242, -0.3945, -0.8203],\n",
       "         ...,\n",
       "         [ 0.7461, -1.0391,  2.4531,  ..., -3.7812,  2.7500, -0.1514],\n",
       "         [ 2.8750, -4.4688,  1.2109,  ...,  1.0156,  0.0131,  3.6250],\n",
       "         [ 3.7812,  1.8203, -1.9453,  ..., -0.1357,  1.7891,  0.1270]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_10': tensor([[ 0.3926, -0.1289, -0.3535,  ...,  0.3145, -0.4551,  0.2773],\n",
       "         [-1.0312, -1.9766, -0.7773,  ..., -1.0703, -0.8633,  0.0070],\n",
       "         [-0.3262,  1.9141,  1.6172,  ..., -1.4219,  0.6680,  0.7969],\n",
       "         ...,\n",
       "         [-0.2754,  0.1104,  0.3633,  ...,  0.3477, -0.2275, -0.0172],\n",
       "         [-0.8320,  0.1748,  0.6797,  ..., -0.0605, -1.0547, -0.3008],\n",
       "         [ 0.4609, -0.4746,  0.0608,  ...,  0.2031,  1.2109,  0.2227]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'mlp_11': tensor([[-1.2109,  0.5664, -1.7812,  ..., -0.5117,  0.3730, -0.5742],\n",
       "         [-1.7422, -1.7188, -4.2500,  ..., -1.9141, -2.2031, -1.2969],\n",
       "         [ 0.2090, -0.5742,  0.2480,  ..., -1.4766,  0.2520,  0.1172],\n",
       "         ...,\n",
       "         [ 1.9531, -2.0625, -1.4062,  ..., -2.3281,  0.4238, -2.0625],\n",
       "         [-4.2188, -0.4512,  3.7188,  ...,  0.8164,  3.1406, -2.4531],\n",
       "         [ 2.0312,  1.8359, -2.3281,  ...,  1.0547,  1.4531,  1.9922]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " 'attn_11': tensor([[ 0.4180,  0.5469,  0.3477,  ...,  0.0781,  0.9883,  0.6562],\n",
       "         [-0.2178, -0.7305, -1.3828,  ..., -2.0625, -0.1060,  0.3633],\n",
       "         [ 0.2578, -0.3184,  0.1084,  ...,  0.5391, -0.1953,  0.9688],\n",
       "         ...,\n",
       "         [-0.1406, -0.3516,  0.3086,  ...,  0.2656,  1.1016, -0.3633],\n",
       "         [-0.2178, -0.0107, -0.0493,  ...,  0.0571, -0.8672,  0.1045],\n",
       "         [ 0.6172,  0.6211, -0.3008,  ...,  0.5273, -1.1016,  2.2500]],\n",
       "        device='cuda:0', dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
