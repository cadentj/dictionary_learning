{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from buffer import AllActivationBuffer\n",
    "from trainers.top_k import TrainerSCAE, AutoEncoderTopK\n",
    "from training import trainSCAE\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "DTYPE = t.float32\n",
    "device = \"cuda:0\" if t.cuda.is_available() else \"cpu\"\n",
    "model = LanguageModel(\"gpt2\", device_map=device, torch_dtype=DTYPE)\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'Skylion007/openwebtext', \n",
    "    split='train', \n",
    "    streaming=True,\n",
    "    trust_remote_code=True\n",
    "    )\n",
    "\n",
    "class CustomData():\n",
    "    def __init__(self, dataset):\n",
    "        self.data = iter(dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return next(self.data)['text']\n",
    "\n",
    "data = CustomData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "expansion = 16\n",
    "k = 128 # TODO: automatically detect these\n",
    "\n",
    "num_features = model.config.n_embd * expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = model.config.n_layer\n",
    "\n",
    "submodules = {}\n",
    "for layer in range(n_layer):\n",
    "    submodules[f\"mlp_{layer}\"] = (model.transformer.h[layer].mlp, \"in_and_out\")\n",
    "    submodules[f\"attn_{layer}\"] = (model.transformer.h[layer].attn, \"out\")\n",
    "\n",
    "# def random_up_features(down_layer):\n",
    "#     # Fake important-connection dictionary, for testing\n",
    "#     dic = {}\n",
    "#     for layer in range(down_layer):\n",
    "#         dic[f\"mlp_{layer}\"]  = t.randint(0, num_features, (num_features, C), dtype=t.long)\n",
    "#         dic[f\"attn_{layer}\"] = t.randint(0, num_features, (num_features, C), dtype=t.long)\n",
    "#     return dic\n",
    "\n",
    "# def all_up_features(down_layer):\n",
    "#     # Fake important-connection dictionary, for testing\n",
    "#     dic = {}\n",
    "#     for layer in range(n_layer):\n",
    "#         dic[f\"mlp_{layer}\"]  = t.randint(0, num_features, (num_features, C), dtype=t.long)\n",
    "#         dic[f\"attn_{layer}\"] = t.randint(0, num_features, (num_features, C), dtype=t.long)\n",
    "#     return dic\n",
    "\n",
    "# important_features = {f\"mlp_{down_layer}\": random_up_features(down_layer) \n",
    "#                       for down_layer in range(n_layer)}\n",
    "important_features = {}\n",
    "                        \n",
    "\n",
    "# Get submodule names from the submodules dictionary\n",
    "submodule_names = list(submodules.keys())\n",
    "\n",
    "pretrained_info = {}\n",
    "for layer in range(n_layer):\n",
    "    for module in ['attn', 'mlp']:\n",
    "        pretrained_info[f'{module}_{layer}'] = {'repo_id': 'jacobcd52/scae', 'filename': f'ae_{module}_{layer}.pt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "buffer = AllActivationBuffer(\n",
    "    data=data,\n",
    "    model=model,\n",
    "    submodules=submodules,\n",
    "    d_submodule=model.config.n_embd, # output dimension of the model component\n",
    "    n_ctxs=128,  # you can set this higher or lower depending on your available memory\n",
    "    device=\"cuda\",\n",
    "    out_batch_size = 512,\n",
    "    refresh_batch_size = 256,\n",
    "    dtype=DTYPE,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerSCAE(\n",
    "        activation_dims={name: model.config.n_embd for name in submodule_names},\n",
    "        dict_sizes={name: model.config.n_embd * expansion for name in submodule_names},\n",
    "        ks={name: k for name in submodule_names},\n",
    "        submodules=submodules,\n",
    "        important_features=important_features,\n",
    "        pretrained_info=pretrained_info,\n",
    "        model_config=model.config,\n",
    "        auxk_alpha=0,\n",
    "        connection_sparsity_coeff=0.1,\n",
    "        use_sparse_connections=False,\n",
    "        seed=None,\n",
    "        device=\"cuda\",\n",
    "        wandb_name=\"SCAE\",\n",
    "        dtype=DTYPE, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac variance explained for mlp_0: 0.9526596069335938\n",
      "frac variance explained for attn_0: 0.9909620881080627\n",
      "frac variance explained for mlp_1: 0.9785271883010864\n",
      "frac variance explained for attn_1: 0.968472957611084\n",
      "frac variance explained for mlp_2: 0.9956282377243042\n",
      "frac variance explained for attn_2: 0.9545985460281372\n",
      "frac variance explained for mlp_3: 0.902158796787262\n",
      "frac variance explained for attn_3: 0.9296982288360596\n",
      "frac variance explained for mlp_4: 0.8518295288085938\n",
      "frac variance explained for attn_4: 0.9151685833930969\n",
      "frac variance explained for mlp_5: 0.8135673999786377\n",
      "frac variance explained for attn_5: 0.9261492490768433\n",
      "frac variance explained for mlp_6: 0.7719327211380005\n",
      "frac variance explained for attn_6: 0.917524516582489\n",
      "frac variance explained for mlp_7: 0.7637858390808105\n",
      "frac variance explained for attn_7: 0.9284847974777222\n",
      "frac variance explained for mlp_8: 0.7614310383796692\n",
      "frac variance explained for attn_8: 0.9162231087684631\n",
      "frac variance explained for mlp_9: 0.7722174525260925\n",
      "frac variance explained for attn_9: 0.9250547289848328\n",
      "frac variance explained for mlp_10: 0.8162675499916077\n",
      "frac variance explained for attn_10: 0.9367557168006897\n",
      "frac variance explained for mlp_11: 0.913667619228363\n",
      "frac variance explained for attn_11: 0.9982013702392578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3233.654052734375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_acts, target_acts = next(buffer)\n",
    "trainer.update(1, input_acts, target_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean loss = 3.413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_evaluation(trainer, buffer, n_batches=100, ce_batch_size=32):\n",
    "    varexp_metrics = {name : {} for name in trainer.submodules.keys()}\n",
    "    ce_metrics = {name : {} for name in trainer.submodules.keys()}\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        # get varexp metrics\n",
    "        input_acts, output_acts = next(buffer)\n",
    "        batch_varexp_metrics = trainer.evaluate_varexp_batch(input_acts, output_acts, use_sparse_connections=False)\n",
    "\n",
    "        # get CE metrics\n",
    "        b = buffer.refresh_batch_size\n",
    "        buffer.refresh_batch_size = ce_batch_size\n",
    "        tokens = buffer.token_batch()\n",
    "        batch_ce_metrics = trainer.evaluate_ce_batch(model, tokens, use_sparse_connections=False)\n",
    "        buffer.refresh_batch_size = b\n",
    "\n",
    "        for name in ce_metrics.keys():\n",
    "            for metric in batch_ce_metrics[name].keys():\n",
    "                ce_metrics[name][metric] = ce_metrics[name].get(metric, 0) + batch_ce_metrics[name][metric]\n",
    "            for metric in batch_varexp_metrics[name].keys():\n",
    "                varexp_metrics[name][metric] = varexp_metrics[name].get(metric, 0) + batch_varexp_metrics[name][metric]\n",
    "    \n",
    "    for name in ce_metrics.keys():\n",
    "        for metric in ce_metrics[name].keys():\n",
    "            ce_metrics[name][metric] = ce_metrics[name][metric] / n_batches\n",
    "        for metric in varexp_metrics[name].keys():\n",
    "            varexp_metrics[name][metric] = varexp_metrics[name][metric] / n_batches\n",
    "        \n",
    "    return varexp_metrics, ce_metrics\n",
    "\n",
    "varexp_metrics, ce_metrics = run_evaluation(trainer, buffer, n_batches=2, ce_batch_size=32)\n",
    "\n",
    "print(f\"Clean loss = {ce_metrics['mlp_0']['loss_original']:.3f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_0   0.009   96%     4.0\n",
      "mlp_1   0.007   98%     5.1\n",
      "mlp_2   0.048   100%     11.0\n",
      "mlp_3   0.007   92%     5.9\n",
      "mlp_4   0.008   87%     7.0\n",
      "mlp_5   0.012   82%     8.3\n",
      "mlp_6   0.017   78%     9.9\n",
      "mlp_7   0.017   77%     11.8\n",
      "mlp_8   0.017   76%     14.4\n",
      "mlp_9   0.021   78%     17.7\n",
      "mlp_10   0.026   82%     24.1\n",
      "mlp_11   0.046   91%     32.3\n",
      "\n",
      "attn_0   0.003   99%    1.5\n",
      "attn_1   -0.000   97%    1.6\n",
      "attn_2   -0.000   95%    1.8\n",
      "attn_3   -0.000   93%    2.3\n",
      "attn_4   0.001   91%    2.8\n",
      "attn_5   0.000   93%    3.0\n",
      "attn_6   0.002   92%    3.6\n",
      "attn_7   0.001   93%    3.8\n",
      "attn_8   0.001   92%    4.8\n",
      "attn_9   0.001   93%    5.6\n",
      "attn_10   0.002   94%    6.8\n",
      "attn_11   0.003   100%    9.1\n"
     ]
    }
   ],
   "source": [
    "for name in [k for k in ce_metrics.keys() if 'mlp' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}   {varexp_metrics[name]['frac_variance_explained']*100:.0f}%     {varexp_metrics[name]['l2_loss']:.1f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for name in [k for k in ce_metrics.keys() if 'attn' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}   {varexp_metrics[name]['frac_variance_explained']*100:.0f}%    {varexp_metrics[name]['l2_loss']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_0   0.016   92%     6.3\n",
      "mlp_1   0.023   97%     6.9\n",
      "mlp_2   4.117   38%     1264.0\n",
      "mlp_3   0.023   84%     8.2\n",
      "mlp_4   0.023   80%     9.3\n",
      "mlp_5   0.023   71%     10.8\n",
      "mlp_6   0.031   69%     12.5\n",
      "mlp_7   0.031   68%     14.8\n",
      "mlp_8   0.031   68%     17.6\n",
      "mlp_9   0.039   69%     21.5\n",
      "mlp_10   0.047   75%     30.4\n",
      "mlp_11   0.062   86%     44.8\n",
      "\n",
      "attn_0   0.016   95%    3.4\n",
      "attn_1   0.008   91%    2.7\n",
      "attn_2   0.008   89%    2.8\n",
      "attn_3   0.016   85%    3.4\n",
      "attn_4   0.016   81%    4.2\n",
      "attn_5   0.008   83%    4.4\n",
      "attn_6   0.016   81%    5.4\n",
      "attn_7   0.016   83%    5.7\n",
      "attn_8   0.016   81%    7.0\n",
      "attn_9   0.016   84%    8.1\n",
      "attn_10   0.016   88%    9.5\n",
      "attn_11   0.023   82%    22.1\n"
     ]
    }
   ],
   "source": [
    "for name in [k for k in ce_metrics.keys() if 'mlp' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}   {varexp_metrics[name]['frac_variance_explained']*100:.0f}%     {varexp_metrics[name]['l2_loss']:.1f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for name in [k for k in ce_metrics.keys() if 'attn' in k]:\n",
    "    print(f\"{name}   {ce_metrics[name]['loss_reconstructed'] - ce_metrics[name]['loss_original']:.3f}   {varexp_metrics[name]['frac_variance_explained']*100:.0f}%    {varexp_metrics[name]['l2_loss']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
